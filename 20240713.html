<!-- 100% privacy-first analytics -->
<script async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>

<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>GraphRAGæœ¬åœ°æ£€ç´¢+Prompt Tuning+covariates(åå˜é‡)+çˆ¬è™«å®ç°GitHubé¡¹ç›®ä»£ç æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œå¿«é€ŸæŒæ¡æœ€æ–°GitHubå¼€æºé¡¹ç›®</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="a8dd0a33-4daf-4ea9-94a9-9be1c757207f" class="page sans"><header><h1 class="page-title">GraphRAGæœ¬åœ°æ£€ç´¢+<strong>Prompt Tuning</strong>+<strong>covariates(åå˜é‡)+çˆ¬è™«å®ç°GitHubé¡¹ç›®ä»£ç æ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œå¿«é€ŸæŒæ¡æœ€æ–°GitHubå¼€æºé¡¹ç›®</strong></h1><p class="page-description"></p></header><div class="page-body"><p id="0495833e-bd4d-4d6a-8bff-f199b79233e0" class="">
</p><h3 id="c8645ec6-54af-4fc6-9f65-6053e18b9875" class=""><strong>ğŸ”¥Prompt Tuning</strong></h3><blockquote id="6fa668da-212e-4bb7-a396-781abd6bac0f" class="">GraphRAGæ˜¯å¾®è½¯ç ”ç©¶é™¢å¼€å‘çš„ä¸€ä¸ªçŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆKnowledge Graph Retrieval-Augmented Generationï¼‰ç³»ç»Ÿã€‚<br/>åœ¨GraphRAGä¸­ï¼ŒPrompt Tuningï¼ˆæç¤ºè°ƒä¼˜ï¼‰æ‰®æ¼”ç€é‡è¦è§’è‰²ï¼Œä¸ºç”¨æˆ·æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”çµæ´»çš„æ–¹å¼æ¥ä¼˜åŒ–å’Œå®šåˆ¶æŸ¥è¯¢ä½“éªŒã€‚ä»¥ä¸‹æ˜¯GraphRAGä¸­Prompt Tuningçš„ä¸»è¦ä¼˜åŠ¿å’Œä½œç”¨ï¼š<br/><h2 id="8d3dfaf6-ff87-4549-be96-7d75f9f11700" class="">ç®€åŒ–é…ç½®è¿‡ç¨‹</h2><ol type="1" id="ebc8b5b3-f98c-4f58-a173-a130999dbd0d" class="numbered-list" start="1"><li><strong>é»˜è®¤æç¤ºæ¨¡æ¿</strong>: GraphRAGæä¾›äº†ä¸€å¥—é»˜è®¤çš„æç¤ºæ¨¡æ¿ï¼Œæ¶µç›–äº†å®ä½“/å…³ç³»æå–ã€æè¿°æ€»ç»“ã€å£°æ˜æå–ç­‰å…³é”®ä»»åŠ¡ã€‚è¿™äº›é¢„è®¾æ¨¡æ¿ä½¿ç”¨æˆ·èƒ½å¤Ÿå¿«é€Ÿå¯åŠ¨å’Œä½¿ç”¨ç³»ç»Ÿï¼Œæ— éœ€å¤æ‚çš„åˆå§‹é…ç½®ã€‚</li></ol><ol type="1" id="d0a7286e-c53f-469b-bc0f-b2f1ae6d46e2" class="numbered-list" start="2"><li><strong>è‡ªåŠ¨æ¨¡æ¿åŒ–</strong>: GraphRAGå¼•å…¥äº†è‡ªåŠ¨æ¨¡æ¿åŒ–åŠŸèƒ½ï¼Œè¯¥åŠŸèƒ½å¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¾“å…¥æ•°æ®å’Œä¸å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„äº¤äº’è‡ªåŠ¨ç”Ÿæˆé€‚åº”ç‰¹å®šé¢†åŸŸçš„æ¨¡æ¿ã€‚è¿™å¤§å¤§é™ä½äº†ç”¨æˆ·çš„å·¥ä½œé‡ï¼ŒåŒæ—¶æé«˜äº†ç³»ç»Ÿå¯¹ä¸åŒé¢†åŸŸæ•°æ®çš„é€‚åº”æ€§ã€‚</li></ol><h2 id="57e719d4-83f6-4c2f-b4ef-1043213462b8" class="">æé«˜æ€§èƒ½å’Œæ•ˆç‡</h2><ol type="1" id="31f4d518-56dc-4110-b3c8-a7bb9eada89d" class="numbered-list" start="1"><li><strong>å‚æ•°é«˜æ•ˆæ€§</strong>: Prompt Tuningåªéœ€æ›´æ–°å°‘é‡çš„æç¤ºå‚æ•°ï¼Œè€Œæ— éœ€å¯¹æ•´ä¸ªé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¿™ç§æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹é€šç”¨èƒ½åŠ›çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—èµ„æºçš„éœ€æ±‚ã€‚</li></ol><ol type="1" id="ad3b2c25-99c7-4ba0-b832-196f331117f4" class="numbered-list" start="2"><li><strong>æ€§èƒ½æ¥è¿‘å®Œå…¨å¾®è°ƒ</strong>: éšç€æ¨¡å‹è§„æ¨¡çš„å¢å¤§ï¼ŒPrompt Tuningçš„æ€§èƒ½è¶Šæ¥è¶Šæ¥è¿‘å®Œå…¨å¾®è°ƒï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šç”šè‡³èƒ½è¶…è¿‡å®Œå…¨å¾®è°ƒã€‚è¿™æ„å‘³ç€ç”¨æˆ·å¯ä»¥è·å¾—æ¥è¿‘å…¨é¢å¾®è°ƒçš„æ€§èƒ½ï¼Œä½†ä»˜å‡ºçš„è®¡ç®—æˆæœ¬è¦ä½å¾—å¤šã€‚</li></ol><ol type="1" id="bd37cd7e-b096-4efd-9462-f3862953cdc4" class="numbered-list" start="3"><li><strong>é«˜æ•ˆæ¨ç†</strong>: ç”±äºåªæ›´æ–°å°‘é‡å‚æ•°ï¼ŒPrompt Tuningä¿ç•™äº†é¢„è®­ç»ƒæ¨¡å‹çš„é«˜æ•ˆæ¨ç†èƒ½åŠ›ã€‚è¿™å¯¹äºéœ€è¦å¿«é€Ÿå“åº”çš„å®æ—¶åº”ç”¨å°¤ä¸ºé‡è¦ã€‚</li></ol><h2 id="3c8a79b5-38ab-4d09-b14d-3d76271169dd" class="">å¢å¼ºé€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›</h2><ol type="1" id="0b2e2027-c33e-4ce0-8df0-1362fdcbd8b3" class="numbered-list" start="1"><li><strong>é¢†åŸŸé€‚åº”æ€§</strong>: é€šè¿‡å°†ä»»åŠ¡ç‰¹å®šçš„ä¿¡æ¯ç¼–ç åœ¨æç¤ºä¸­ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å‚æ•°ä¸å˜ï¼ŒPrompt Tuningåœ¨é¢†åŸŸè¿ç§»é—®é¢˜ä¸Šè¡¨ç°æ›´å¥½ã€‚è¿™ä½¿å¾—GraphRAGèƒ½å¤Ÿæ›´å®¹æ˜“åœ°é€‚åº”ä¸åŒçš„çŸ¥è¯†é¢†åŸŸå’Œåº”ç”¨åœºæ™¯ã€‚</li></ol><ol type="1" id="edb2bf7a-ba9f-4704-bd36-4f9236f86b0e" class="numbered-list" start="2"><li><strong>æç¤ºé›†æˆ</strong>: GraphRAGå…è®¸å­¦ä¹ å¤šä¸ªæç¤ºå¹¶è¿›è¡Œé›†æˆï¼Œè¿™ç§æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æé«˜ç³»ç»Ÿæ€§èƒ½ï¼Œå¹¶æä¾›æ›´åŠ çµæ´»çš„æŸ¥è¯¢ç­–ç•¥ã€‚</li></ol><h2 id="55cf6bfb-a0ac-4c3b-87a8-a2c274741e8e" class="">æé«˜å¯è§£é‡Šæ€§å’Œå¯æ§æ€§</h2><ol type="1" id="df9b9324-c53c-497c-aaa0-c3add7299dde" class="numbered-list" start="1"><li><strong>å¯è§£é‡Šæ€§</strong>: å­¦ä¹ åˆ°çš„æç¤ºå‚æ•°å…·æœ‰ä¸€å®šçš„å¯è§£é‡Šæ€§ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·ç†è§£æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™å¯¹äºéœ€è¦é€æ˜åº¦å’Œå¯è§£é‡Šæ€§çš„åº”ç”¨åœºæ™¯éå¸¸æœ‰ä»·å€¼ã€‚</li></ol><ol type="1" id="4bf60707-9dae-460a-81b8-bb276b722af5" class="numbered-list" start="2"><li><strong>ç²¾ç»†æ§åˆ¶</strong>: é€šè¿‡æ‰‹åŠ¨é…ç½®é€‰é¡¹ï¼Œé«˜çº§ç”¨æˆ·å¯ä»¥å¯¹æç¤ºè¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶å’Œè°ƒæ•´ã€‚è¿™ä¸ºä¸“ä¸šç”¨æˆ·æä¾›äº†æ›´å¤§çš„çµæ´»æ€§å’Œå®šåˆ¶åŒ–èƒ½åŠ›ã€‚</li></ol><h2 id="82cf7688-5478-458c-a32b-0ac8bc3e8091" class="">ä¼˜åŒ–çŸ¥è¯†å›¾è°±æ„å»º</h2><ol type="1" id="bcd5a7c2-8c44-48ae-af58-91c3223eb31a" class="numbered-list" start="1"><li><strong>å®ä½“å’Œå…³ç³»æå–</strong>: Prompt Tuningä¼˜åŒ–äº†å®ä½“è¯†åˆ«å’Œå…³ç³»æå–çš„è¿‡ç¨‹ï¼Œæé«˜äº†çŸ¥è¯†å›¾è°±æ„å»ºçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚</li></ol><ol type="1" id="83c502f0-ab1d-48e1-8f8b-a078cf281a29" class="numbered-list" start="2"><li><strong>æè¿°æ€»ç»“</strong>: é€šè¿‡ä¼˜åŒ–çš„æç¤ºï¼Œç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°ç”Ÿæˆå®ä½“å’Œå…³ç³»çš„æè¿°æ‘˜è¦ï¼Œä¸°å¯Œäº†çŸ¥è¯†å›¾è°±çš„å†…å®¹ã€‚</li></ol><ol type="1" id="eb303bb4-f1ae-4c5c-a33d-fc1284187304" class="numbered-list" start="3"><li><strong>ç¤¾åŒºæŠ¥å‘Šç”Ÿæˆ</strong>: Prompt Tuningè¿˜æ”¹è¿›äº†ç¤¾åŒºæŠ¥å‘Šçš„ç”Ÿæˆè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ‘˜è¦ã€å½±å“è¯„ä¼°å’Œå…³é”®å‘ç°çš„æå–ï¼Œä½¿å¾—ç”Ÿæˆçš„æŠ¥å‘Šæ›´åŠ å…¨é¢å’Œæœ‰æ´å¯ŸåŠ›ã€‚</li></ol><p id="8137d4a5-4fc7-4958-8dc7-3ddd01a80672" class="">GraphRAGä¸­çš„Prompt TuningæŠ€æœ¯é€šè¿‡æä¾›çµæ´»ã€é«˜æ•ˆä¸”æ˜“äºä½¿ç”¨çš„æç¤ºè°ƒä¼˜æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„æ€§èƒ½ã€é€‚åº”æ€§å’Œå¯ç”¨æ€§ã€‚å®ƒä¸ä»…ç®€åŒ–äº†ç”¨æˆ·çš„æ“ä½œæµç¨‹ï¼Œè¿˜åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä¸ºçŸ¥è¯†å›¾è°±æ£€ç´¢å¢å¼ºç”Ÿæˆä»»åŠ¡æä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚</p><p id="e26adf82-994c-4510-bec1-fd7e9eae2746" class="">
</p></blockquote><p id="edb1ddc1-fa28-4847-9f12-a9758b573d0e" class="">
</p><h3 id="b3787f9e-1b09-4056-9314-aa08d3a34cfe" class=""><strong>ğŸ”¥</strong>covariates(åå˜é‡)</h3><blockquote id="8f048c50-9d94-4641-946e-cb7b52cb2a25" class="">GraphRAGä¸­çš„covariates(åå˜é‡)æ˜¯ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†,å…·æœ‰ä»¥ä¸‹å‡ ä¸ªå…³é”®ä½œç”¨å’Œä¼˜åŠ¿:<ol type="1" id="2d1d218e-74f2-4f13-b811-184b69728006" class="numbered-list" start="1"><li><strong>æä¾›ç»“æ„åŒ–å£°æ˜ä¿¡æ¯</strong><br/>Covariatesä»£è¡¨ä»æ–‡æœ¬ä¸­æå–çš„å…³äºå®ä½“çš„ç»“æ„åŒ–å£°æ˜æˆ–é™ˆè¿°ä¿¡æ¯,è¿™äº›ä¿¡æ¯å¯èƒ½æ˜¯æ—¶é—´ç›¸å…³çš„ã€‚å®ƒä»¬ä½œä¸ºGraphRAGçŸ¥è¯†æ¨¡å‹çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†,ä¸å®ä½“ã€å…³ç³»ç­‰ä¸€èµ·æ„æˆäº†å®Œæ•´çš„çŸ¥è¯†å›¾è°±ç»“æ„ã€‚<br/></li></ol><ol type="1" id="1c76b31f-fcfd-4041-a9c6-266a2a1cf6f5" class="numbered-list" start="2"><li><strong>å¢å¼ºä¸Šä¸‹æ–‡ç†è§£</strong><br/>Covariatesä¸ºçŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“å’Œå…³ç³»æä¾›äº†é¢å¤–çš„ä¸Šä¸‹æ–‡å’Œç»†èŠ‚ä¿¡æ¯ã€‚è¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯å¯ä»¥è¢«åˆ©ç”¨æ¥ç”Ÿæˆæ›´ç›¸å…³å’Œè¿è´¯çš„æŸ¥è¯¢å“åº”ã€‚<br/></li></ol><ol type="1" id="782078b3-574c-49f8-948d-82f344c4ac0a" class="numbered-list" start="3"><li><strong>æ•è·ç»†ç²’åº¦çŸ¥è¯†</strong><br/>é€šè¿‡åŒ…å«covariates,GraphRAGèƒ½å¤Ÿä»æºæ–‡æ¡£ä¸­æ•è·æ›´ç»†è‡´å’Œå…¨é¢çš„çŸ¥è¯†,è€Œä¸ä»…ä»…æ˜¯ç®€å•çš„å®ä½“-å…³ç³»ä¿¡æ¯ã€‚è¿™ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„æŸ¥è¯¢å’Œæ¨ç†ä»»åŠ¡ã€‚<br/></li></ol><ol type="1" id="6fa5effb-d3e1-4309-9034-4c738c80098c" class="numbered-list" start="4"><li><strong>æ”¯æŒé«˜çº§æ¨ç†</strong><br/>Covariatesä½¿GraphRAGèƒ½å¤Ÿåœ¨çŸ¥è¯†å›¾è°±ä¸Šæ‰§è¡Œæ›´é«˜çº§çš„æ¨ç†å’Œæ¨æ–­,è¶…è¶Šäº†ç®€å•çš„äº‹å®æ£€ç´¢ã€‚å®ƒä»¬æ•è·çš„å…³ç³»å’Œå±æ€§ä¿¡æ¯å…è®¸ç³»ç»Ÿå‘ç°éšå«çš„è¿æ¥å¹¶å¾—å‡ºæ–°çš„è§è§£ã€‚<br/></li></ol><ol type="1" id="706ef6ce-7b7f-4bb2-aca4-93ffb6a419e8" class="numbered-list" start="5"><li><strong>æ”¹è¿›ä¿¡æ¯å¯è§£é‡Šæ€§</strong><br/>ä½œä¸ºæ•´ä½“çŸ¥è¯†å›¾è°±çš„ä¸€éƒ¨åˆ†,covariatesçš„ç»“æ„åŒ–è¡¨ç¤ºä½¿ä¿¡æ¯æ›´æ˜“äºè¯­è¨€æ¨¡å‹ç»„ä»¶è®¿é—®å’Œè§£é‡Šã€‚è¿™ç§ç»“æ„åŒ–æ•°æ®å¯ä»¥æ›´æœ‰æ•ˆåœ°é›†æˆåˆ°å“åº”ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚<br/></li></ol><ol type="1" id="941ba9cd-c706-43f8-b9c8-d98a85ce924c" class="numbered-list" start="6"><li><strong>ä¼˜åŒ–ç¤¾åŒºæŠ¥å‘Šç”Ÿæˆ</strong><br/>åœ¨GraphRAGçš„ç¤¾åŒºæŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­,covariatesä¿¡æ¯è¢«ç”¨äºç”Ÿæˆæ›´å…¨é¢å’Œæœ‰æ´å¯ŸåŠ›çš„æ‘˜è¦ã€å½±å“è¯„ä¼°å’Œå…³é”®å‘ç°ã€‚<br/></li></ol><ol type="1" id="f7bdf004-0d73-406b-a808-0d381e39a54b" class="numbered-list" start="7"><li><strong>æ”¯æŒæ—¶åºåˆ†æ</strong><br/>ç”±äºcovariateså¯ä»¥åŒ…å«æ—¶é—´ç›¸å…³çš„ä¿¡æ¯,å®ƒä»¬ä½¿GraphRAGèƒ½å¤Ÿæ‰§è¡Œæ—¶åºåˆ†æå’Œè·Ÿè¸ªå®ä½“éšæ—¶é—´çš„å˜åŒ–ã€‚<br/></li></ol><p id="e84396fc-cafc-4844-bdf5-34d45906c2a4" class="">covariatesä½œä¸ºGraphRAGæ–¹æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†,æä¾›äº†å®è´µçš„ä¸Šä¸‹æ–‡ä¿¡æ¯,å¹¶ä½¿ç³»ç»Ÿèƒ½å¤Ÿæ‰§è¡Œæ¯”ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆç³»ç»Ÿæ›´å¤æ‚çš„æ¨ç†å’Œæ€»ç»“ä»»åŠ¡ã€‚å®ƒä»¬æå¤§åœ°å¢å¼ºäº†GraphRAGçš„çŸ¥è¯†è¡¨ç¤ºèƒ½åŠ›å’ŒæŸ¥è¯¢å¤„ç†èƒ½åŠ›ã€‚</p></blockquote><p id="932cddef-dc3c-4e4c-beba-8b390a4581f5" class="">
</p><h3 id="821dfb73-053e-4466-ad91-26bbf65db77f" class="">ğŸ”¥ä»£ç æ£€ç´¢åŠŸèƒ½</h3><blockquote id="6ef3bd03-b47b-4e81-9814-7731548dca24" class="">ä½¿ç”¨GraphRAGæ¥ä¸ºGitHubä¸Šçš„å¼€æºé¡¹ç›®æ„å»ºRAGç³»ç»Ÿä»¥ä¾¿å¿«é€Ÿæ£€ç´¢ä»£ç å…·æœ‰ä»¥ä¸‹å‡ ä¸ªä¸»è¦ä¼˜åŠ¿:<h3 id="ab7f5580-8114-48e1-9506-45f480ecc2fb" class="">æé«˜æ£€ç´¢æ€§èƒ½å’Œå‡†ç¡®æ€§</h3><p id="f343983d-f852-4687-982c-b0d9a536fd41" class="">GraphRAGé€šè¿‡ç»“åˆçŸ¥è¯†å›¾è°±å’Œå¤§å‹è¯­è¨€æ¨¡å‹,èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œè¿æ¥ä»£ç åº“ä¸­çš„å„ä¸ªç»„ä»¶ä¹‹é—´çš„å…³ç³»ã€‚è¿™ç§æ–¹æ³•å¯ä»¥:</p><ul id="2d84c5ac-3c51-42a7-b918-489c73249f0d" class="bulleted-list"><li style="list-style-type:disc">æ•æ‰ä»£ç ç»“æ„å’Œä¾èµ–å…³ç³»,æä¾›æ›´ç²¾å‡†çš„æ£€ç´¢ç»“æœ</li></ul><ul id="d585cec3-19bb-4c15-bad5-7e69fa433c1a" class="bulleted-list"><li style="list-style-type:disc">ç†è§£ä»£ç çš„è¯­ä¹‰å’Œä¸Šä¸‹æ–‡,è€Œä¸ä»…ä»…æ˜¯åŸºäºå…³é”®è¯åŒ¹é…</li></ul><ul id="853c0530-0129-48dc-826e-91f114e110e7" class="bulleted-list"><li style="list-style-type:disc">è¿æ¥åˆ†æ•£åœ¨ä¸åŒæ–‡ä»¶æˆ–æ¨¡å—ä¸­çš„ç›¸å…³ä»£ç ç‰‡æ®µ</li></ul><h3 id="b7bc2905-a27b-4260-91a9-6676bf065afb" class="">é™ä½è®¡ç®—å’Œå­˜å‚¨æˆæœ¬</h3><p id="a3746ce5-2014-4a84-955f-b6f29736ded7" class="">ä¸ä¼ ç»Ÿçš„RAGç³»ç»Ÿç›¸æ¯”,GraphRAGå¯ä»¥æ›´é«˜æ•ˆåœ°å­˜å‚¨å’Œæ£€ç´¢ä¿¡æ¯[3]:</p><ul id="20437df6-08b4-4683-a1f4-494942ea366b" class="bulleted-list"><li style="list-style-type:disc">å‡å°‘å†—ä½™æ•°æ®å­˜å‚¨,å› ä¸ºå…³ç³»ä¿¡æ¯è¢«ç¼–ç åœ¨å›¾ç»“æ„ä¸­</li></ul><ul id="ad70159b-b1ed-4a93-bc3e-494303b9b8b8" class="bulleted-list"><li style="list-style-type:disc">åŠ å¿«æ£€ç´¢é€Ÿåº¦,é€šè¿‡å›¾éå†è€Œä¸æ˜¯å…¨æ–‡æœç´¢</li></ul><ul id="2e88bc24-34a3-40ce-bb7a-27a4d47539d8" class="bulleted-list"><li style="list-style-type:disc">é™ä½å¤„ç†å¤§å‹ä»£ç åº“æ‰€éœ€çš„è®¡ç®—èµ„æº</li></ul><h3 id="5cc00f89-a206-4d7b-9da5-f70897104060" class="">GraphRAGçš„æ¨¡å—åŒ–è®¾è®¡ä½¿å…¶æ›´å®¹æ˜“é€‚åº”ä¸åŒçš„ä»£ç åº“å’Œé¡¹ç›®ç»“æ„:</h3><ul id="49f3a786-b359-4e0a-986a-4b40499aea2e" class="bulleted-list"><li style="list-style-type:disc">å¯ä»¥è½»æ¾åœ°æ·»åŠ æ–°çš„ä»£ç ç»„ä»¶æˆ–æ›´æ–°ç°æœ‰å…³ç³»</li></ul><ul id="e4254c24-0bc2-46f6-a0d6-f28795542c36" class="bulleted-list"><li style="list-style-type:disc">æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶çš„é›†æˆ</li></ul><h3 id="f4cb58ac-2f50-42a3-891f-901f7b447e89" class="">å¢å¼ºä»£ç ç†è§£å’Œæ–‡æ¡£ç”Ÿæˆ</h3><p id="7a7b583f-bab7-4494-9dac-a5e5436e399f" class="">é€šè¿‡åˆ©ç”¨GraphRAGçš„çŸ¥è¯†å›¾è°±ç»“æ„,å¯ä»¥:</p><ul id="0182049d-8ed9-43a9-a68a-db48ab78d148" class="bulleted-list"><li style="list-style-type:disc">è‡ªåŠ¨ç”Ÿæˆæ›´å…¨é¢å’Œå‡†ç¡®çš„ä»£ç æ–‡æ¡£</li></ul><ul id="31f3ecd2-35a6-46a8-8cec-fd1437ac1279" class="bulleted-list"><li style="list-style-type:disc">æä¾›ä»£ç ç»“æ„å’Œä¾èµ–å…³ç³»çš„å¯è§†åŒ–</li></ul><ul id="57fcc914-c105-4157-98a0-85922b3c959c" class="bulleted-list"><li style="list-style-type:disc">è¾…åŠ©å¼€å‘è€…å¿«é€Ÿç†è§£å¤æ‚çš„ä»£ç åº“</li></ul><h3 id="e4a73ef9-bb01-441b-99b0-6d72b9f0e6e7" class="">æ”¯æŒé«˜çº§æŸ¥è¯¢å’Œåˆ†æ</h3><p id="9cf70e6b-0d60-43c5-a1f1-c4eb0b868bc6" class="">GraphRAGå…è®¸è¿›è¡Œæ›´å¤æ‚å’Œè¯­ä¹‰åŒ–çš„ä»£ç æŸ¥è¯¢:</p><ul id="afa3d023-393b-4c9e-be95-36a23006ccee" class="bulleted-list"><li style="list-style-type:disc">å¯ä»¥æ‰§è¡ŒåŸºäºè·¯å¾„å’Œæ¨¡å¼çš„æœç´¢</li></ul><ul id="8bbd0611-29d3-485e-9c29-cc12ada404ea" class="bulleted-list"><li style="list-style-type:disc">æ”¯æŒè·¨æ–‡ä»¶å’Œæ¨¡å—çš„å…³ç³»æŸ¥è¯¢</li></ul><ul id="c15c4e09-f3de-49bf-b456-5b5d77a6d00a" class="bulleted-list"><li style="list-style-type:disc">èƒ½å¤Ÿå›ç­”å…³äºä»£ç ç»“æ„ã€è®¾è®¡æ¨¡å¼å’Œæœ€ä½³å®è·µçš„é—®é¢˜</li></ul><p id="bcd584e2-4a6b-452f-b96c-3e098852e03a" class="">ä½¿ç”¨GraphRAGæ¥æ„å»ºGitHubé¡¹ç›®çš„RAGç³»ç»Ÿå¯ä»¥æ˜¾è‘—æé«˜ä»£ç æ£€ç´¢çš„æ•ˆç‡å’Œè´¨é‡,åŒæ—¶ä¸ºå¼€å‘è€…æä¾›æ›´æ·±å…¥çš„ä»£ç ç†è§£å’Œåˆ†æèƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•ä¸ä»…å¯ä»¥åŠ é€Ÿå¼€å‘è¿‡ç¨‹,è¿˜èƒ½ä¿ƒè¿›æ›´å¥½çš„ä»£ç é‡ç”¨å’ŒçŸ¥è¯†å…±äº«ã€‚</p></blockquote><p id="6e13c386-51e8-43dc-8897-83ca56ff23be" class="">
</p><p id="64c65daa-9125-40bb-b311-51570f4412f6" class="">
</p><h2 id="1f53c383-0216-4e14-865a-04bbd2277353" class=""><strong>ğŸ‘‰ğŸ‘‰ğŸ‘‰å¦‚æœ‰é—®é¢˜è¯·è”ç³»æˆ‘çš„å¾½ä¿¡ stoeng</strong></h2><h2 id="02d4d425-dc3a-41eb-9c22-d09d572634f1" class=""><strong>ğŸ”¥ğŸ”¥ğŸ”¥æœ¬é¡¹ç›®ä»£ç ç”±AIè¶…å…ƒåŸŸé¢‘é“åˆ¶ä½œï¼Œè§‚çœ‹æ›´å¤šå¤§æ¨¡å‹å¾®è°ƒè§†é¢‘è¯·è®¿é—®æˆ‘çš„é¢‘é“â¬‡</strong></h2><h3 id="b6b9288b-c742-4dfd-bd23-74b599344fe6" class=""><strong>ğŸ‘‰ğŸ‘‰ğŸ‘‰</strong><strong><a href="https://space.bilibili.com/3493277319825652">æˆ‘çš„å“”å“©å“”å“©é¢‘é“</a></strong></h3><h3 id="ed9047d8-4ebb-4cfd-b497-14380d3014e1" class=""><strong>ğŸ‘‰ğŸ‘‰ğŸ‘‰</strong><strong><a href="https://www.youtube.com/@AIsuperdomain">æˆ‘çš„YouTubeé¢‘é“</a></strong></h3><h3 id="98f64764-c941-49e2-82bb-73807bd79679" class=""><strong>ğŸ‘‰ğŸ‘‰ğŸ‘‰æˆ‘çš„å¼€æºé¡¹ç›® </strong><strong><a href="https://github.com/win4r/AISuperDomain">https://github.com/win4r/AISuperDomain</a></strong></h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="c4df2773-7f94-42a0-ac14-2f99a84ae520" class="code"><code class="language-Shell">claim_extraction:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  enabled: true
  prompt: &quot;prompts/claim_extraction.txt&quot;
  description: &quot;Any claims or facts that could be relevant to information discovery.&quot;
  max_gleanings: 1

##Just uncomment the enabled line in your settings.yaml file.
##I&#x27;ll resolve the issue, but please reopen if this doesn&#x27;t work</code></pre><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="2bb36b1f-a5fc-4283-8b9c-a13f31fd47fd" class="code"><code class="language-Shell">
pip install graphrag

python -m graphrag.index --init  --root . 
python -m graphrag.index --root . 
###æç¤ºä¼˜åŒ–
python -m graphrag.prompt_tune --root . --no-entity-types

GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE=&quot;prompts/entity_extraction.txt&quot;

GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE=&quot;prompts/community_report.txt&quot;

GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE=&quot;prompts/summarize_descriptions.txt&quot;



è®¾ç½®env
GRAPHRAG_API_KEY=sk-proj-wDPaUDu1Iim



export GRAPHRAG_API_KEY=&quot;sk-xggd2443fg&quot;
export GRAPHRAG_LLM_MODEL=&quot;gpt-3.5-turbo&quot;
export GRAPHRAG_EMBEDDING_MODEL=&quot;text-embedding-ada-002&quot;

export GRAPHRAG_ENTITY_EXTRACTION_PROMPT_FILE=&quot;prompts/entity_extraction.txt&quot;
export GRAPHRAG_COMMUNITY_REPORT_PROMPT_FILE=&quot;prompts/community_report.txt&quot;
export GRAPHRAG_SUMMARIZE_DESCRIPTIONS_PROMPT_FILE=&quot;prompts/summarize_descriptions.txt&quot;



python -m graphrag.query \
--root . \
--method local \
&quot;how to install crawl4ai?&quot;</code></pre><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="606fbd9a-fa9e-4502-a5c0-27948678be0d" class="code"><code class="language-Shell">
###settings.yaml

encoding_model: cl100k_base
skip_workflows: []
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: openai_chat # or azure_openai_chat
  model: gpt-3.5-turbo-0125
  model_supports_json: true # recommended if this is available for your model.
  # max_tokens: 4000
  # request_timeout: 180.0
  # api_base: https://&lt;instance&gt;.openai.azure.com
  # api_version: 2024-02-15-preview
  # organization: &lt;organization_id&gt;
  # deployment_name: &lt;azure_model_deployment_name&gt;
  # tokens_per_minute: 150_000 # set a leaky bucket throttle
  # requests_per_minute: 10_000 # set a leaky bucket throttle
  # max_retries: 10
  # max_retry_wait: 10.0
  # sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times
  # concurrent_requests: 25 # the number of parallel inflight requests that may be made

parallelization:
  stagger: 0.3
  # num_threads: 50 # the number of threads to use for parallel processing

async_mode: threaded # or asyncio

embeddings:
  ## parallelization: override the global parallelization settings for embeddings
  async_mode: threaded # or asyncio
  llm:
    api_key: ${GRAPHRAG_API_KEY}
    type: openai_embedding # or azure_openai_embedding
    model: text-embedding-3-small
    # api_base: https://&lt;instance&gt;.openai.azure.com
    # api_version: 2024-02-15-preview
    # organization: &lt;organization_id&gt;
    # deployment_name: &lt;azure_model_deployment_name&gt;
    # tokens_per_minute: 150_000 # set a leaky bucket throttle
    # requests_per_minute: 10_000 # set a leaky bucket throttle
    # max_retries: 10
    # max_retry_wait: 10.0
    # sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times
    # concurrent_requests: 25 # the number of parallel inflight requests that may be made
    # batch_size: 16 # the number of documents to send in a single request
    # batch_max_tokens: 8191 # the maximum number of tokens to send in a single request
    # target: required # or optional
  


chunks:
  size: 300
  overlap: 100
  group_by_columns: [id] # by default, we don&#x27;t allow chunks to cross documents
    
input:
  type: file # or blob
  file_type: text # or csv
  base_dir: &quot;input&quot;
  file_encoding: utf-8
  file_pattern: &quot;.*\\.txt$&quot;

cache:
  type: file # or blob
  base_dir: &quot;cache&quot;
  # connection_string: &lt;azure_blob_storage_connection_string&gt;
  # container_name: &lt;azure_blob_storage_container_name&gt;

storage:
  type: file # or blob
  base_dir: &quot;inputs/artifacts&quot;
  # connection_string: &lt;azure_blob_storage_connection_string&gt;
  # container_name: &lt;azure_blob_storage_container_name&gt;

reporting:
  type: file # or console, blob
  base_dir: &quot;inputs/reports&quot;
  # connection_string: &lt;azure_blob_storage_connection_string&gt;
  # container_name: &lt;azure_blob_storage_container_name&gt;

entity_extraction:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: &quot;prompts/entity_extraction.txt&quot;
  entity_types: [organization,person,geo,event]
  max_gleanings: 0

summarize_descriptions:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: &quot;prompts/summarize_descriptions.txt&quot;
  max_length: 500

claim_extraction:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  # enabled: true
  prompt: &quot;prompts/claim_extraction.txt&quot;
  description: &quot;Any claims or facts that could be relevant to information discovery.&quot;
  max_gleanings: 0

community_report:
  ## llm: override the global llm settings for this task
  ## parallelization: override the global parallelization settings for this task
  ## async_mode: override the global async_mode settings for this task
  prompt: &quot;prompts/community_report.txt&quot;
  max_length: 2000
  max_input_length: 8000

cluster_graph:
  max_cluster_size: 10

embed_graph:
  enabled: false # if true, will generate node2vec embeddings for nodes
  # num_walks: 10
  # walk_length: 40
  # window_size: 2
  # iterations: 3
  # random_seed: 597832

umap:
  enabled: false # if true, will generate UMAP embeddings for nodes

snapshots:
  graphml: false
  raw_entities: false
  top_level_nodes: false

local_search:
  # text_unit_prop: 0.5
  # community_prop: 0.1
  # conversation_history_max_turns: 5
  # top_k_mapped_entities: 10
  # top_k_relationships: 10
  # max_tokens: 12000

global_search:
  # max_tokens: 12000
  # data_max_tokens: 12000
  # map_max_tokens: 1000
  # reduce_max_tokens: 2000
  # concurrency: 32
</code></pre><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="635aca94-840f-4e84-bf9e-13b636b308ac" class="code"><code class="language-Shell">import os
import asyncio
import pandas as pd
import tiktoken
from rich import print
from typing import List

# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œç±»
from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey
from graphrag.query.indexer_adapters import (
    read_indexer_covariates,
    read_indexer_entities,
    read_indexer_relationships,
    read_indexer_reports,
    read_indexer_text_units,
)
from graphrag.query.input.loaders.dfs import store_entity_semantic_embeddings
from graphrag.query.llm.oai.chat_openai import ChatOpenAI
from graphrag.query.llm.oai.embedding import OpenAIEmbedding
from graphrag.query.llm.oai.typing import OpenaiApiType
from graphrag.query.question_gen.local_gen import LocalQuestionGen
from graphrag.query.structured_search.local_search.mixed_context import LocalSearchMixedContext
from graphrag.query.structured_search.local_search.search import LocalSearch
from graphrag.vector_stores.lancedb import LanceDBVectorStore

# è®¾ç½®å¸¸é‡å’Œé…ç½®
INPUT_DIR = &quot;/Users/charlesqin/PycharmProjects/RAGCode/inputs/artifacts&quot;
LANCEDB_URI = f&quot;{INPUT_DIR}/lancedb&quot;
COMMUNITY_REPORT_TABLE = &quot;create_final_community_reports&quot;
ENTITY_TABLE = &quot;create_final_nodes&quot;
ENTITY_EMBEDDING_TABLE = &quot;create_final_entities&quot;
RELATIONSHIP_TABLE = &quot;create_final_relationships&quot;
COVARIATE_TABLE = &quot;create_final_covariates&quot;
TEXT_UNIT_TABLE = &quot;create_final_text_units&quot;
COMMUNITY_LEVEL = 2


async def setup_llm_and_embedder():
    &quot;&quot;&quot;
    è®¾ç½®è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒåµŒå…¥æ¨¡å‹
    &quot;&quot;&quot;
    api_key = os.environ[&quot;GRAPHRAG_API_KEY&quot;]
    llm_model = os.environ.get(&quot;GRAPHRAG_LLM_MODEL&quot;, &quot;gpt-3.5-turbo&quot;)
    embedding_model = os.environ.get(&quot;GRAPHRAG_EMBEDDING_MODEL&quot;, &quot;text-embedding-3-small&quot;)

    # åˆå§‹åŒ–ChatOpenAIå®ä¾‹
    llm = ChatOpenAI(
        api_key=api_key,
        model=llm_model,
        api_type=OpenaiApiType.OpenAI,
        max_retries=20,
    )

    # åˆå§‹åŒ–tokenç¼–ç å™¨
    token_encoder = tiktoken.get_encoding(&quot;cl100k_base&quot;)

    # åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹
    text_embedder = OpenAIEmbedding(
        api_key=api_key,
        api_base=None,
        api_type=OpenaiApiType.OpenAI,
        model=embedding_model,
        deployment_name=embedding_model,
        max_retries=20,
    )

    return llm, token_encoder, text_embedder


async def load_context():
    &quot;&quot;&quot;
    åŠ è½½ä¸Šä¸‹æ–‡æ•°æ®ï¼ŒåŒ…æ‹¬å®ä½“ã€å…³ç³»ã€æŠ¥å‘Šã€æ–‡æœ¬å•å…ƒå’Œåå˜é‡
    &quot;&quot;&quot;
    # è¯»å–å®ä½“æ•°æ®
    entity_df = pd.read_parquet(f&quot;{INPUT_DIR}/{ENTITY_TABLE}.parquet&quot;)
    entity_embedding_df = pd.read_parquet(f&quot;{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet&quot;)
    entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)

    # è®¾ç½®å’ŒåŠ è½½å®ä½“æè¿°åµŒå…¥
    description_embedding_store = LanceDBVectorStore(collection_name=&quot;entity_description_embeddings&quot;)
    description_embedding_store.connect(db_uri=LANCEDB_URI)
    store_entity_semantic_embeddings(entities=entities, vectorstore=description_embedding_store)

    # è¯»å–å…³ç³»æ•°æ®
    relationship_df = pd.read_parquet(f&quot;{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet&quot;)
    relationships = read_indexer_relationships(relationship_df)

    # è¯»å–ç¤¾åŒºæŠ¥å‘Šæ•°æ®
    report_df = pd.read_parquet(f&quot;{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet&quot;)
    reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)

    # è¯»å–æ–‡æœ¬å•å…ƒæ•°æ®
    text_unit_df = pd.read_parquet(f&quot;{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet&quot;)
    text_units = read_indexer_text_units(text_unit_df)

    # è¯»å–å’Œå¤„ç†åå˜é‡æ•°æ®
    covariate_df = pd.read_parquet(f&quot;{INPUT_DIR}/{COVARIATE_TABLE}.parquet&quot;)
    claims = read_indexer_covariates(covariate_df)
    print(f&quot;Claim records: {len(claims)}&quot;)
    covariates = {&quot;claims&quot;: claims}

    return entities, relationships, reports, text_units, description_embedding_store, covariates


async def setup_search_engine(llm, token_encoder, text_embedder, entities, relationships, reports, text_units,
                              description_embedding_store, covariates):
    &quot;&quot;&quot;
    è®¾ç½®æœç´¢å¼•æ“ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡æ„å»ºå™¨å’Œæœç´¢å‚æ•°
    &quot;&quot;&quot;
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ„å»ºå™¨
    context_builder = LocalSearchMixedContext(
        community_reports=reports,
        text_units=text_units,
        entities=entities,
        relationships=relationships,
        covariates=covariates,
        entity_text_embeddings=description_embedding_store,
        embedding_vectorstore_key=EntityVectorStoreKey.ID,
        text_embedder=text_embedder,
        token_encoder=token_encoder,
    )

    # è®¾ç½®æœ¬åœ°ä¸Šä¸‹æ–‡å‚æ•°
    local_context_params = {
        &quot;text_unit_prop&quot;: 0.5,
        &quot;community_prop&quot;: 0.1,
        &quot;conversation_history_max_turns&quot;: 5,
        &quot;conversation_history_user_turns_only&quot;: True,
        &quot;top_k_mapped_entities&quot;: 10,
        &quot;top_k_relationships&quot;: 10,
        &quot;include_entity_rank&quot;: True,
        &quot;include_relationship_weight&quot;: True,
        &quot;include_community_rank&quot;: False,
        &quot;return_candidate_context&quot;: False,
        &quot;embedding_vectorstore_key&quot;: EntityVectorStoreKey.ID,
        &quot;max_tokens&quot;: 12_000,
    }

    # è®¾ç½®è¯­è¨€æ¨¡å‹å‚æ•°
    llm_params = {
        &quot;max_tokens&quot;: 2_000,
        &quot;temperature&quot;: 0.0,
    }

    # åˆå§‹åŒ–æœ¬åœ°æœç´¢å¼•æ“
    search_engine = LocalSearch(
        llm=llm,
        context_builder=context_builder,
        token_encoder=token_encoder,
        llm_params=llm_params,
        context_builder_params=local_context_params,
        response_type=&quot;multiple paragraphs&quot;,
    )

    return search_engine, context_builder, llm_params, local_context_params


async def run_search(search_engine, query: str):
    &quot;&quot;&quot;
    æ‰§è¡Œæœç´¢æŸ¥è¯¢
    &quot;&quot;&quot;
    result = await search_engine.asearch(query)
    return result


async def generate_questions(question_generator, history: List[str]):
    &quot;&quot;&quot;
    åŸºäºå†å²ç”Ÿæˆæ–°çš„é—®é¢˜
    &quot;&quot;&quot;
    questions = await question_generator.agenerate(
        question_history=history, context_data=None, question_count=5
    )
    return questions


async def main():
    &quot;&quot;&quot;
    ä¸»å‡½æ•°ï¼Œè¿è¡Œæ•´ä¸ªæœç´¢å’Œé—®é¢˜ç”Ÿæˆæµç¨‹
    &quot;&quot;&quot;
    try:
        # è®¾ç½®è¯­è¨€æ¨¡å‹å’ŒåµŒå…¥å™¨
        llm, token_encoder, text_embedder = await setup_llm_and_embedder()

        # åŠ è½½ä¸Šä¸‹æ–‡æ•°æ®
        entities, relationships, reports, text_units, description_embedding_store, covariates = await load_context()

        # è®¾ç½®æœç´¢å¼•æ“
        search_engine, context_builder, llm_params, local_context_params = await setup_search_engine(
            llm, token_encoder, text_embedder, entities, relationships, reports, text_units,
            description_embedding_store, covariates
        )

        # è¿è¡Œæœç´¢ç¤ºä¾‹
        queries = [
            &quot;how to take a screenshot of the page in crawl4ai?&quot;,
            &quot;how to set a custom user agent in crawl4ai?&quot;,
            &quot;tell me what is Extraction Strategies and show some examples in crawl4ai.&quot;,
        ]

        for query in queries:
            print(f&quot;\n[bold]Query:[/bold] {query}&quot;)
            result = await run_search(search_engine, query)
            print(f&quot;[bold]Response:[/bold]\n{result.response}&quot;)
            print(&quot;\n[bold]Context Data:[/bold]&quot;)
            print(&quot;Entities:&quot;)
            print(result.context_data[&quot;entities&quot;].head())
            print(&quot;\nRelationships:&quot;)
            print(result.context_data[&quot;relationships&quot;].head())
            print(&quot;\nReports:&quot;)
            print(result.context_data[&quot;reports&quot;].head())
            print(&quot;\nSources:&quot;)
            print(result.context_data[&quot;sources&quot;].head())
            if &quot;claims&quot; in result.context_data:
                print(&quot;\nClaims:&quot;)
                print(result.context_data[&quot;claims&quot;].head())

        # é—®é¢˜ç”Ÿæˆ
        question_generator = LocalQuestionGen(
            llm=llm,
            context_builder=context_builder,
            token_encoder=token_encoder,
            llm_params=llm_params,
            context_builder_params=local_context_params,
        )

        question_history = [
            &quot;how to take a screenshot of the page in crawl4ai?&quot;,
            &quot;how to set a custom user agent in crawl4ai?&quot;,
            &quot;tell me what is Extraction Strategies and show some examples in crawl4ai.&quot;,
        ]
        print(&quot;\n[bold]Generating questions based on history:[/bold]&quot;)
        print(f&quot;History: {question_history}&quot;)
        candidate_questions = await generate_questions(question_generator, question_history)
        print(&quot;Generated questions:&quot;)
        for i, question in enumerate(candidate_questions.response, 1):
            print(f&quot;{i}. {question}&quot;)

    except Exception as e:
        print(f&quot;[bold red]An error occurred:[/bold red] {str(e)}&quot;)


if __name__ == &quot;__main__&quot;:
    # è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main())</code></pre><h3 id="85ae90b9-b5c4-483f-8cd6-750b27a38382" class="">çˆ¬è™«</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4a70dc5c-fd99-4ed1-96e1-12581bad748c" class="code"><code class="language-Shell">
#pip install scrapy html2text bs4

import scrapy
from scrapy.crawler import CrawlerProcess
from bs4 import BeautifulSoup
import html2text
import os
import json
from urllib.parse import urlparse

class ContentFocusedSpider(scrapy.Spider):
    name = &#x27;content_focused_spider&#x27;
    start_urls = [&#x27;https://crawl4ai.com/mkdocs/&#x27;]
    allowed_domains = [&#x27;crawl4ai.com&#x27;]

    def __init__(self, *args, **kwargs):
        super(ContentFocusedSpider, self).__init__(*args, **kwargs)
        self.h = html2text.HTML2Text()
        self.h.ignore_links = True
        self.h.ignore_images = True
        self.h.ignore_emphasis = True
        self.h.body_width = 0
        self.results = []
        
        os.makedirs(&#x27;.data&#x27;, exist_ok=True)
        os.makedirs(&#x27;.data/markdown_files&#x27;, exist_ok=True)

    def parse(self, response):
        # ä½¿ç”¨ BeautifulSoup æå–ä¸»è¦å†…å®¹
        soup = BeautifulSoup(response.text, &#x27;html.parser&#x27;)
        
        # ç§»é™¤å¯¼èˆªæ ã€ä¾§è¾¹æ ã€é¡µè„šç­‰å…ƒç´ 
        for elem in soup([&#x27;nav&#x27;, &#x27;header&#x27;, &#x27;footer&#x27;, &#x27;aside&#x27;]):
            elem.decompose()
        
        # å°è¯•æ‰¾åˆ°ä¸»è¦å†…å®¹åŒºåŸŸ
        main_content = soup.find(&#x27;main&#x27;) or soup.find(&#x27;article&#x27;) or soup.find(&#x27;div&#x27;, class_=&#x27;content&#x27;)
        
        if main_content:
            content = str(main_content)
        else:
            content = str(soup.body)  # å¦‚æœæ‰¾ä¸åˆ°æ˜ç¡®çš„ä¸»è¦å†…å®¹ï¼Œä½¿ç”¨æ•´ä¸ª body

        # è½¬æ¢ä¸º Markdown
        markdown_content = self.h.handle(content)

        # ç”Ÿæˆæ–‡ä»¶åå¹¶ä¿å­˜
        parsed_url = urlparse(response.url)
        file_path = parsed_url.path.strip(&#x27;/&#x27;).replace(&#x27;/&#x27;, &#x27;_&#x27;) or &#x27;index&#x27;
        markdown_filename = f&#x27;.data/markdown_files/{file_path}.md&#x27;
        
        with open(markdown_filename, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f:
            f.write(markdown_content)
        
        result = {
            &#x27;url&#x27;: response.url,
            &#x27;markdown_file&#x27;: markdown_filename,
        }
        self.results.append(result)
        
        # ç»§ç»­çˆ¬å–å…¶ä»–é“¾æ¥
        for link in response.css(&#x27;a::attr(href)&#x27;).getall():
            yield response.follow(link, self.parse)

    def closed(self, reason):
        with open(&#x27;.data/markdown_results.json&#x27;, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        print(f&quot;çˆ¬å–å®Œæˆã€‚æ€»å…±çˆ¬å–äº† {len(self.results)} ä¸ªé¡µé¢&quot;)
        print(&quot;ç»“æœå…ƒæ•°æ®ä¿å­˜åœ¨ .data/markdown_results.json&quot;)
        print(&quot;Markdown æ–‡ä»¶ä¿å­˜åœ¨ .data/markdown_files/ ç›®å½•ä¸‹&quot;)

process = CrawlerProcess(settings={
    &#x27;USER_AGENT&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#x27;,
    &#x27;ROBOTSTXT_OBEY&#x27;: True,
    &#x27;CONCURRENT_REQUESTS&#x27;: 1,
    &#x27;DOWNLOAD_DELAY&#x27;: 2,
})

process.crawl(ContentFocusedSpider)
process.start()</code></pre><p id="6277de1c-b696-4254-9a2e-3c0a4a71fa2a" class="">
</p><h3 id="7ece3940-f172-4588-823c-4b7fdf7e0caf" class="">fastapi</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="4a86498d-5117-4423-8089-81558c169552" class="code"><code class="language-Shell">#pip install fastapi uvicorn

#æµ‹è¯•å‘½ä»¤
#curl -X POST &quot;http://localhost:8012/v1/completions&quot; -H &quot;Content-Type: application/json&quot; -d &#x27;{&quot;prompt&quot;: &quot;how to take a screenshot of the page in crawl4ai?&quot;}&#x27;
#curl -X POST &quot;http://localhost:8012/v1/question_generation&quot; -H &quot;Content-Type: application/json&quot; -d &#x27;{&quot;question_history&quot;: [&quot;how to take a screenshot of the page in crawl4ai?&quot;, &quot;how to set a custom user agent in crawl4ai?&quot;], &quot;question_count&quot;: 5}&#x27;

import os
import asyncio
import time
import pandas as pd
import tiktoken
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional

# å¯¼å…¥å¿…è¦çš„GraphRAGæ¨¡å—å’Œç±»
from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey
from graphrag.query.indexer_adapters import (
    read_indexer_covariates,
    read_indexer_entities,
    read_indexer_relationships,
    read_indexer_reports,
    read_indexer_text_units,
)
from graphrag.query.input.loaders.dfs import store_entity_semantic_embeddings
from graphrag.query.llm.oai.chat_openai import ChatOpenAI
from graphrag.query.llm.oai.embedding import OpenAIEmbedding
from graphrag.query.llm.oai.typing import OpenaiApiType
from graphrag.query.question_gen.local_gen import LocalQuestionGen
from graphrag.query.structured_search.local_search.mixed_context import LocalSearchMixedContext
from graphrag.query.structured_search.local_search.search import LocalSearch
from graphrag.vector_stores.lancedb import LanceDBVectorStore

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI()

# è®¾ç½®å¸¸é‡å’Œé…ç½®
INPUT_DIR = &quot;/Users/charlesqin/PycharmProjects/RAGCode/inputs/artifacts&quot;
LANCEDB_URI = f&quot;{INPUT_DIR}/lancedb&quot;
COMMUNITY_REPORT_TABLE = &quot;create_final_community_reports&quot;
ENTITY_TABLE = &quot;create_final_nodes&quot;
ENTITY_EMBEDDING_TABLE = &quot;create_final_entities&quot;
RELATIONSHIP_TABLE = &quot;create_final_relationships&quot;
COVARIATE_TABLE = &quot;create_final_covariates&quot;
TEXT_UNIT_TABLE = &quot;create_final_text_units&quot;
COMMUNITY_LEVEL = 2

# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æœç´¢å¼•æ“å’Œé—®é¢˜ç”Ÿæˆå™¨
search_engine = None
question_generator = None


# å®šä¹‰APIè¯·æ±‚çš„æ•°æ®æ¨¡å‹
class Query(BaseModel):
    prompt: str
    max_tokens: Optional[int] = 2000
    temperature: Optional[float] = 0.0


class QuestionGenRequest(BaseModel):
    question_history: List[str]
    question_count: Optional[int] = 5


async def setup_llm_and_embedder():
    &quot;&quot;&quot;
    è®¾ç½®è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒåµŒå…¥æ¨¡å‹
    &quot;&quot;&quot;
    api_key = os.environ[&quot;GRAPHRAG_API_KEY&quot;]
    llm_model = os.environ.get(&quot;GRAPHRAG_LLM_MODEL&quot;, &quot;gpt-3.5-turbo&quot;)
    embedding_model = os.environ.get(&quot;GRAPHRAG_EMBEDDING_MODEL&quot;, &quot;text-embedding-3-small&quot;)

    # åˆå§‹åŒ–ChatOpenAIå®ä¾‹
    llm = ChatOpenAI(
        api_key=api_key,
        model=llm_model,
        api_type=OpenaiApiType.OpenAI,
        max_retries=20,
    )

    # åˆå§‹åŒ–tokenç¼–ç å™¨
    token_encoder = tiktoken.get_encoding(&quot;cl100k_base&quot;)

    # åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹
    text_embedder = OpenAIEmbedding(
        api_key=api_key,
        api_base=None,
        api_type=OpenaiApiType.OpenAI,
        model=embedding_model,
        deployment_name=embedding_model,
        max_retries=20,
    )

    return llm, token_encoder, text_embedder


async def load_context():
    &quot;&quot;&quot;
    åŠ è½½ä¸Šä¸‹æ–‡æ•°æ®ï¼ŒåŒ…æ‹¬å®ä½“ã€å…³ç³»ã€æŠ¥å‘Šã€æ–‡æœ¬å•å…ƒå’Œåå˜é‡
    &quot;&quot;&quot;
    # è¯»å–å®ä½“æ•°æ®
    entity_df = pd.read_parquet(f&quot;{INPUT_DIR}/{ENTITY_TABLE}.parquet&quot;)
    entity_embedding_df = pd.read_parquet(f&quot;{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet&quot;)
    entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)

    # è®¾ç½®å’ŒåŠ è½½å®ä½“æè¿°åµŒå…¥
    description_embedding_store = LanceDBVectorStore(collection_name=&quot;entity_description_embeddings&quot;)
    description_embedding_store.connect(db_uri=LANCEDB_URI)
    store_entity_semantic_embeddings(entities=entities, vectorstore=description_embedding_store)

    # è¯»å–å…³ç³»æ•°æ®
    relationship_df = pd.read_parquet(f&quot;{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet&quot;)
    relationships = read_indexer_relationships(relationship_df)

    # è¯»å–ç¤¾åŒºæŠ¥å‘Šæ•°æ®
    report_df = pd.read_parquet(f&quot;{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet&quot;)
    reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)

    # è¯»å–æ–‡æœ¬å•å…ƒæ•°æ®
    text_unit_df = pd.read_parquet(f&quot;{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet&quot;)
    text_units = read_indexer_text_units(text_unit_df)

    # è¯»å–å’Œå¤„ç†åå˜é‡æ•°æ®
    covariate_df = pd.read_parquet(f&quot;{INPUT_DIR}/{COVARIATE_TABLE}.parquet&quot;)
    claims = read_indexer_covariates(covariate_df)
    print(f&quot;Claim records: {len(claims)}&quot;)
    covariates = {&quot;claims&quot;: claims}

    return entities, relationships, reports, text_units, description_embedding_store, covariates


async def setup_search_engine(llm, token_encoder, text_embedder, entities, relationships, reports, text_units,
                              description_embedding_store, covariates):
    &quot;&quot;&quot;
    è®¾ç½®æœç´¢å¼•æ“ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡æ„å»ºå™¨å’Œæœç´¢å‚æ•°
    &quot;&quot;&quot;
    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ„å»ºå™¨
    context_builder = LocalSearchMixedContext(
        community_reports=reports,
        text_units=text_units,
        entities=entities,
        relationships=relationships,
        covariates=covariates,
        entity_text_embeddings=description_embedding_store,
        embedding_vectorstore_key=EntityVectorStoreKey.ID,
        text_embedder=text_embedder,
        token_encoder=token_encoder,
    )

    # è®¾ç½®æœ¬åœ°ä¸Šä¸‹æ–‡å‚æ•°
    local_context_params = {
        &quot;text_unit_prop&quot;: 0.5,
        &quot;community_prop&quot;: 0.1,
        &quot;conversation_history_max_turns&quot;: 5,
        &quot;conversation_history_user_turns_only&quot;: True,
        &quot;top_k_mapped_entities&quot;: 10,
        &quot;top_k_relationships&quot;: 10,
        &quot;include_entity_rank&quot;: True,
        &quot;include_relationship_weight&quot;: True,
        &quot;include_community_rank&quot;: False,
        &quot;return_candidate_context&quot;: False,
        &quot;embedding_vectorstore_key&quot;: EntityVectorStoreKey.ID,
        &quot;max_tokens&quot;: 12_000,
    }

    # è®¾ç½®è¯­è¨€æ¨¡å‹å‚æ•°
    llm_params = {
        &quot;max_tokens&quot;: 2_000,
        &quot;temperature&quot;: 0.0,
    }

    # åˆå§‹åŒ–æœ¬åœ°æœç´¢å¼•æ“
    search_engine = LocalSearch(
        llm=llm,
        context_builder=context_builder,
        token_encoder=token_encoder,
        llm_params=llm_params,
        context_builder_params=local_context_params,
        response_type=&quot;multiple paragraphs&quot;,
    )

    return search_engine, context_builder, llm_params, local_context_params


@app.on_event(&quot;startup&quot;)
async def startup_event():
    &quot;&quot;&quot;
    åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–äº‹ä»¶
    &quot;&quot;&quot;
    global search_engine, question_generator

    # è®¾ç½®è¯­è¨€æ¨¡å‹å’ŒåµŒå…¥å™¨
    llm, token_encoder, text_embedder = await setup_llm_and_embedder()

    # åŠ è½½ä¸Šä¸‹æ–‡æ•°æ®
    entities, relationships, reports, text_units, description_embedding_store, covariates = await load_context()

    # è®¾ç½®æœç´¢å¼•æ“
    search_engine, context_builder, llm_params, local_context_params = await setup_search_engine(
        llm, token_encoder, text_embedder, entities, relationships, reports, text_units,
        description_embedding_store, covariates
    )

    # è®¾ç½®é—®é¢˜ç”Ÿæˆå™¨
    question_generator = LocalQuestionGen(
        llm=llm,
        context_builder=context_builder,
        token_encoder=token_encoder,
        llm_params=llm_params,
        context_builder_params=local_context_params,
    )


@app.post(&quot;/v1/completions&quot;)
async def create_completion(query: Query):
    &quot;&quot;&quot;
    å¤„ç†æ–‡æœ¬è¡¥å…¨è¯·æ±‚çš„APIç«¯ç‚¹
    &quot;&quot;&quot;
    if not search_engine:
        raise HTTPException(status_code=500, detail=&quot;æœç´¢å¼•æ“æœªåˆå§‹åŒ–&quot;)

    try:
        # æ‰§è¡Œæœç´¢
        result = await search_engine.asearch(query.prompt)
        # è¿”å›æ ¼å¼åŒ–çš„å“åº”
        return {
            &quot;id&quot;: &quot;cmpl-&quot; + os.urandom(12).hex(),
            &quot;object&quot;: &quot;text_completion&quot;,
            &quot;created&quot;: int(time.time()),
            &quot;model&quot;: &quot;graphrag-local-search&quot;,
            &quot;choices&quot;: [
                {
                    &quot;text&quot;: result.response,
                    &quot;index&quot;: 0,
                    &quot;logprobs&quot;: None,
                    &quot;finish_reason&quot;: &quot;stop&quot;
                }
            ],
            &quot;usage&quot;: {
                &quot;prompt_tokens&quot;: len(query.prompt.split()),
                &quot;completion_tokens&quot;: len(result.response.split()),
                &quot;total_tokens&quot;: len(query.prompt.split()) + len(result.response.split())
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post(&quot;/v1/question_generation&quot;)
async def generate_questions(request: QuestionGenRequest):
    &quot;&quot;&quot;
    å¤„ç†é—®é¢˜ç”Ÿæˆè¯·æ±‚çš„APIç«¯ç‚¹
    &quot;&quot;&quot;
    if not question_generator:
        raise HTTPException(status_code=500, detail=&quot;é—®é¢˜ç”Ÿæˆå™¨æœªåˆå§‹åŒ–&quot;)

    try:
        # ç”Ÿæˆå€™é€‰é—®é¢˜
        candidate_questions = await question_generator.agenerate(
            question_history=request.question_history,
            context_data=None,
            question_count=request.question_count
        )
        # è¿”å›æ ¼å¼åŒ–çš„å“åº”
        return {
            &quot;id&quot;: &quot;qgen-&quot; + os.urandom(12).hex(),
            &quot;object&quot;: &quot;question_generation&quot;,
            &quot;created&quot;: int(time.time()),
            &quot;model&quot;: &quot;graphrag-question-generator&quot;,
            &quot;choices&quot;: [
                {
                    &quot;questions&quot;: candidate_questions.response,
                    &quot;index&quot;: 0
                }
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == &quot;__main__&quot;:
    # ä½¿ç”¨uvicornè¿è¡ŒFastAPIåº”ç”¨
    import uvicorn

    uvicorn.run(app, host=&quot;0.0.0.0&quot;, port=8012)</code></pre><h3 id="ada1a07a-1460-4cde-a069-bb4cfc6b8d9e" class="">chainlit</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="26ae6031-64ac-46e4-976e-6ae960d9cb5c" class="code"><code class="language-Shell">#pip install chainlit
import os
import aiohttp
import chainlit as cl
import logging

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œé˜²æ­¢ Chainlit åŠ è½½ .env æ–‡ä»¶
os.environ[&quot;CHAINLIT_AUTO_LOAD_DOTENV&quot;] = &quot;false&quot;

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

API_BASE_URL = &quot;http://localhost:8012&quot;  # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨äº†8012ç«¯å£ï¼Œè¯·ç¡®ä¿ä¸æ‚¨çš„APIç«¯å£ä¸€è‡´


class CustomAsyncClient:
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.chat = self.Chat(base_url)

    class Chat:
        def __init__(self, base_url: str):
            self.base_url = base_url
            self.completions = self.Completions(base_url)

        class Completions:
            def __init__(self, base_url: str):
                self.base_url = base_url

            async def create(self, messages: list, **kwargs):
                logger.info(f&quot;Sending request to {self.base_url}/v1/completions&quot;)
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.post(
                                f&quot;{self.base_url}/v1/completions&quot;,
                                json={&quot;prompt&quot;: messages[-1][&quot;content&quot;], **kwargs}
                        ) as response:
                            logger.info(f&quot;Received response with status {response.status}&quot;)
                            if response.status == 200:
                                data = await response.json()
                                logger.info(f&quot;Response data: {data}&quot;)
                                return data
                            else:
                                error_text = await response.text()
                                logger.error(f&quot;API request failed with status {response.status}: {error_text}&quot;)
                                raise Exception(f&quot;API request failed with status {response.status}: {error_text}&quot;)
                except Exception as e:
                    logger.error(f&quot;Error in create method: {str(e)}&quot;)
                    raise


client = CustomAsyncClient(API_BASE_URL)

settings = {
    &quot;model&quot;: &quot;graphrag-local-search&quot;,
    &quot;temperature&quot;: 0,
}


@cl.on_message
async def on_message(message: cl.Message):
    logger.info(f&quot;Received message: {message.content}&quot;)
    try:
        # å‘é€&quot;å¤„ç†ä¸­&quot;çš„æ¶ˆæ¯
        processing_message = cl.Message(content=&quot;Processing your request...&quot;)
        await processing_message.send()

        response = await client.chat.completions.create(
            messages=[
                {
                    &quot;content&quot;: &quot;You are a helpful bot based on GraphRAG&quot;,
                    &quot;role&quot;: &quot;system&quot;
                },
                {
                    &quot;content&quot;: message.content,
                    &quot;role&quot;: &quot;user&quot;
                }
            ],
            **settings
        )

        response_content = response[&#x27;choices&#x27;][0][&#x27;text&#x27;]
        logger.info(f&quot;Sending response: {response_content}&quot;)

        # åˆ›å»ºæ–°æ¶ˆæ¯è€Œä¸æ˜¯æ›´æ–°æ—§æ¶ˆæ¯
        await cl.Message(content=response_content).send()

        # ç§»é™¤&quot;å¤„ç†ä¸­&quot;çš„æ¶ˆæ¯
        await processing_message.remove()

    except Exception as e:
        logger.error(f&quot;Error in on_message: {str(e)}&quot;)
        error_message = f&quot;An error occurred: {str(e)}&quot;
        # åˆ›å»ºæ–°çš„é”™è¯¯æ¶ˆæ¯
        await cl.Message(content=error_message).send()
        # ç§»é™¤&quot;å¤„ç†ä¸­&quot;çš„æ¶ˆæ¯
        await processing_message.remove()


@cl.on_chat_start
async def on_chat_start():
    logger.info(&quot;New chat started&quot;)
    await cl.Message(content=&quot;Welcome! I&#x27;m your GraphRAG assistant. How can I help you today?&quot;).send()


if __name__ == &quot;__main__&quot;:
    logger.info(&quot;Starting Chainlit application&quot;)
    cl.run()

</code></pre></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>
